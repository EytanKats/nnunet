{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "import hashlib\n",
    "\n",
    "# Script constants\n",
    "UPLOAD_KEY = 'UPLOAD'\n",
    "DESCRIPTION_PLACEHOLDER = 'YOUR_DESCRIPTION_HERE'\n",
    "SELECTION_FILEPATH = \"./nnunet_wandb_selection.txt\"\n",
    "\n",
    "# wandb constants\n",
    "WANDB_TEAM_NAME = \"test-team-mdl\"\n",
    "WANDB_PROJECT = \"nnUNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust paths if necessary\n",
    "\n",
    "TRAINED_MODELS_PATH = os.environ['RESULTS_FOLDER']\n",
    "# TRAINED_MODELS_PATH = \"/share/data_rechenknecht01_2/weihsbach/nnunet/nnUNet_trained_models\"\n",
    "RAW_DATA_BASE_PATH = os.environ['nnUNet_raw_data_base']\n",
    "# RAW_DATA_BASE_PATH = \"/share/data_rechenknecht01_2/weihsbach/nnunet/nnUNet_raw_data_base\"\n",
    "\n",
    "INFERENCE_PATH = \"/data_rechenknecht01_2/weihsbach/nnunet/nnUNet_inference_output\"\n",
    "\n",
    "UPLOAD_MODEL_FILES = False\n",
    "COLLECT_PREDICTIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sha256sum(filename):\n",
    "    # see https://stackoverflow.com/questions/22058048/hashing-a-file-in-python\n",
    "    hash_method  = hashlib.sha256()\n",
    "    barr  = bytearray(128*1024)\n",
    "    m_view = memoryview(barr)\n",
    "    with open(filename, 'rb', buffering=0) as f:\n",
    "        while cnt := f.readinto(m_view):\n",
    "            hash_method.update(m_view[:cnt])\n",
    "    return hash_method.hexdigest()\n",
    "\n",
    "def retrieve_model_infos(model_pkl_path):\n",
    "    model_path = Path(model_pkl_path.replace(\".model.pkl\", \".model\"))\n",
    "    model_pkl_path = Path(model_pkl_path)\n",
    "\n",
    "    model_basepath = Path(model_path).parent\n",
    "    metadata_filepath = Path(model_basepath, \"debug.json\")\n",
    "\n",
    "    if metadata_filepath.is_file() and model_pkl_path.is_file() and model_path.is_file():\n",
    "        # Collect data keys\n",
    "\n",
    "        with open(metadata_filepath, 'r') as metadata_file:\n",
    "            metadata  = json.load(metadata_file)\n",
    "        task_name = metadata['dataset_directory'].split(\"/\")[-1]\n",
    "\n",
    "        torch_model = torch.load(model_path)\n",
    "        model_type = re.match(r\".*model_(.*?).model\", str(model_path)).groups()[0]\n",
    "        trainer_name = metadata['experiment_name']\n",
    "\n",
    "        fold = metadata['fold']\n",
    "        epoch = torch_model['epoch']\n",
    "        configuration = re.match(r\".*/nnUNet/(.*?)/Task\\d{3}\", str(model_path)).groups()[0]\n",
    "        user = os.environ['USER']\n",
    "\n",
    "        loss_train_data = torch_model['plot_stuff'][0]\n",
    "        loss_val_data = torch_model['plot_stuff'][1]\n",
    "        eval_metric_data = torch_model['plot_stuff'][3]\n",
    "\n",
    "        plot_data = {'training/loss':loss_train_data, 'validation/loss':loss_val_data, 'eval/dice':eval_metric_data}\n",
    "        config_dict = dict(\n",
    "            task_name=task_name,\n",
    "            last_epoch=epoch,\n",
    "            fold=fold,\n",
    "            configuration=configuration,\n",
    "            uploading_user=user,\n",
    "            trainer_name=trainer_name,\n",
    "            model_type=model_type,\n",
    "            model_path=model_path,\n",
    "            model_hash=sha256sum(model_path),\n",
    "            model_pkl_path=model_pkl_path,\n",
    "            model_pkl_hash=sha256sum(model_pkl_path),\n",
    "        )\n",
    "        return model_basepath, config_dict, plot_data, metadata\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "def get_summary_json_paths(*base_paths):\n",
    "    all_json_paths = []\n",
    "    for _path in base_paths:\n",
    "        # Read trained model files from nnUNet directory\n",
    "        all_json_paths.extend(glob.glob(_path + \"/**/summary.json\", recursive=True))\n",
    "\n",
    "    all_json_paths = [Path(_path) for _path in all_json_paths]\n",
    "    return sorted(all_json_paths)\n",
    "\n",
    "def get_model_pkl_paths(*base_paths):\n",
    "    all_trained_model_paths = []\n",
    "    for _path in base_paths:\n",
    "        # Read trained model files from nnUNet directory\n",
    "        all_trained_model_paths.extend(glob.glob(_path + \"/**/*model.pkl\", recursive=True))\n",
    "\n",
    "    all_trained_model_paths = [Path(_path) for _path in all_trained_model_paths]\n",
    "    return sorted(all_trained_model_paths)\n",
    "\n",
    "def extract_summary_metrics(summary_json_path):\n",
    "    with open(summary_json_path, 'r') as json_file:\n",
    "        summary = json.load(json_file)\n",
    "\n",
    "    file_results = summary['results']['all']\n",
    "    target_filenames = [entry['test'].split(\"/\")[-1] for entry in file_results]\n",
    "    class_numstrings = [entry for entry in file_results[0].keys() if entry.isnumeric()]\n",
    "    # metrics = list(file_results[0][class_nums[0]].keys())\n",
    "    metrics = ['Dice', 'Jaccard', 'Precision', 'Recall']\n",
    "    # summary_id = summary['id']\n",
    "    table_dict = {}\n",
    "    # \"prediction/filename/metric/\" per class\n",
    "    for f_idx, f_name in enumerate(target_filenames):\n",
    "        for met in metrics:\n",
    "            data = []\n",
    "            for c_numstr in class_numstrings:\n",
    "                metric_val = file_results[f_idx][c_numstr][met]\n",
    "                data.append([int(c_numstr), metric_val])\n",
    "            table = wandb.Table(data=data, columns=[\"class id\", met])\n",
    "            # table_dict[f'prediction/{summary_id}/{f_name}/{met}'] = table\n",
    "            table_dict[f'prediction/{f_name}/{met}'] = table\n",
    "            \n",
    "    return table_dict\n",
    "\n",
    "def get_best_model_path(task_name, all_model_paths):\n",
    "    final_models = list(filter(lambda elem: \"model_final_checkpoint.model.pkl\" in str(elem) and task_name in str(elem), all_model_paths))\n",
    "    best_models = list(filter(lambda elem: \"model_best_checkpoint.model.pkl\" in str(elem) and task_name in str(elem), all_model_paths))\n",
    "    latest_models = list(filter(lambda elem: \"model_latest_checkpoint.model.pkl\" in str(elem) and task_name in str(elem), all_model_paths))\n",
    "\n",
    "    if final_models:\n",
    "        return final_models[0]\n",
    "    elif best_models: \n",
    "        return best_models[0]\n",
    "    elif latest_models:\n",
    "        return latest_models[0]\n",
    "    return None\n",
    "\n",
    "def find_best_fitting_model(summary_json_path, all_trained_model_paths):\n",
    "\n",
    "    from difflib import SequenceMatcher\n",
    "\n",
    "    def string_similarity(str_a, str_b):\n",
    "        return SequenceMatcher(None, str_a, str_b).ratio()\n",
    "\n",
    "    best_model_path = None\n",
    "    best_similarity = 0.0\n",
    "\n",
    "    for model_path in all_trained_model_paths:\n",
    "        similarity = string_similarity(str(model_path), str(summary_json_path))\n",
    "\n",
    "        if similarity > best_similarity:\n",
    "            best_model_path = model_path\n",
    "            best_similarity = similarity\n",
    "    \n",
    "    return best_model_path, all_trained_model_paths.index(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check available models (and prediction scores) and write selection file for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get existing hashes of online project\n",
    "api = wandb.Api()\n",
    "existing_model_hashes = [run.config.get('model_pkl_hash',\"\") for run in api.runs(f\"{WANDB_TEAM_NAME}/{WANDB_PROJECT}\")]\n",
    "existing_notes = [run.notes for run in api.runs(f\"{WANDB_TEAM_NAME}/{WANDB_PROJECT}\")]\n",
    "\n",
    "all_trained_model_paths = get_model_pkl_paths(TRAINED_MODELS_PATH)\n",
    "all_summary_json_paths = get_summary_json_paths(TRAINED_MODELS_PATH, INFERENCE_PATH)\n",
    "\n",
    "with open(SELECTION_FILEPATH, 'w') as selection_file:\n",
    "    selection_file.write(f\"# Change SKIP/EXISTS entry to {UPLOAD_KEY} for all models that shall be uploaded\\n\")\n",
    "    for m_idx, m_path in enumerate(all_trained_model_paths):\n",
    "        sha = sha256sum(m_path)\n",
    "        if sha in existing_model_hashes:\n",
    "            idx = existing_model_hashes.index(sha)\n",
    "            description = existing_notes[idx] if existing_notes[idx] != None else DESCRIPTION_PLACEHOLDER\n",
    "            file_key = \"EXISTS\"\n",
    "        else:\n",
    "            description = DESCRIPTION_PLACEHOLDER\n",
    "            file_key = \"SKIP\"\n",
    "\n",
    "        selection_file.write(f\"{file_key};\\t{description};\\t\\tMODEL {m_idx:4d};\\t\\t{m_path}\\n\")\n",
    "\n",
    "if COLLECT_PREDICTIONS:\n",
    "    with open(SELECTION_FILEPATH, 'a') as mapping_file:\n",
    "        mapping_file.write(\"\\n\")   \n",
    "        mapping_file.write(\"\\n\")   \n",
    "        mapping_file.write(f\"# Remove ? before mapping to upload summary data alongside model. Modify mapping numbers if needed.\\n\")\n",
    "        \n",
    "        for summary_idx, _path in enumerate(all_summary_json_paths):\n",
    "            best_model_path, model_idx = find_best_fitting_model(_path, all_trained_model_paths)\n",
    "            mapping_file.write(f\"?MAP SUMMARY{summary_idx:4d} -> MODEL {model_idx:4d}\\n\")\n",
    "        mapping_file.write(\"\\n\")  \n",
    "\n",
    "        for summary_idx, _path in enumerate(all_summary_json_paths):\n",
    "            mapping_file.write(f\"# SUMMARY{summary_idx:4d}; {_path}\\n\")\n",
    "        mapping_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Now select all models to be uploaded in file \"./nnunet_wandb_selection.txt\" (SKIP -> SAVE) and modify mapping to prediction scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_double_whitespace(whitespace_string):\n",
    "    return ' '.join(whitespace_string.split())\n",
    "summary_mapping_dict = {}\n",
    "summary_path_dict = {}\n",
    "\n",
    "with open(SELECTION_FILEPATH, 'r') as selection_file:\n",
    "    # Check mappings\n",
    "    for line in iter(selection_file):\n",
    "        if line.startswith(\"MAP\"):\n",
    "            mapping_string, *_ = line.split(';')\n",
    "            summary_id, model_id = re.match(r\"MAP (SUMMARY\\s*\\d{1,4}) -> (MODEL\\s*\\d{1,4})\", mapping_string).groups()\n",
    "            summary_mapping_dict[shrink_double_whitespace(model_id)] = shrink_double_whitespace(summary_id)\n",
    "\n",
    "with open(SELECTION_FILEPATH, 'r') as selection_file:\n",
    "    # Check summaries\n",
    "    for line in iter(selection_file):\n",
    "        if line.startswith(\"# SUMMARY\"):\n",
    "            summary_id, json_path = line.split(';')\n",
    "            summary_id = re.match(r\".*?(SUMMARY\\s*\\d{1,4})\", summary_id).groups()[0]\n",
    "            json_path = json_path.replace('#', '').strip()\n",
    "            summary_path_dict[shrink_double_whitespace(summary_id)] = json_path\n",
    "\n",
    "\n",
    "with open(SELECTION_FILEPATH, 'r') as selection_file:\n",
    "    # Check upload selections\n",
    "    for line in iter(selection_file):\n",
    "        # Check all file lines with model paths to upload to wandb\n",
    "        if not line.startswith(UPLOAD_KEY):\n",
    "            continue\n",
    "\n",
    "        split_line = line.split(\";\")\n",
    "        if len(split_line) != 4:\n",
    "            warnings.warn(f\"Error in entry {line}\")\n",
    "            continue\n",
    "\n",
    "        line_command, user_description, model_id, model_pkl_path = split_line\n",
    "        line_command, user_description, model_id, model_pkl_path = \\\n",
    "            line_command.strip(), user_description.strip(), shrink_double_whitespace(model_id), model_pkl_path.strip()\n",
    "\n",
    "        if model_id in summary_mapping_dict:\n",
    "            json_summary_path = summary_path_dict[summary_mapping_dict[model_id]]\n",
    "            summary_tables = extract_summary_metrics(json_summary_path)\n",
    "        else:\n",
    "            summary_tables = {}\n",
    "\n",
    "        model_basepath, config_dict, plot_data, metadata = retrieve_model_infos(model_pkl_path)\n",
    "\n",
    "        long_name = \\\n",
    "            f\"{config_dict['task_name']}\" \\\n",
    "            f\"__{config_dict['configuration']}\" \\\n",
    "            f\"__{config_dict['trainer_name']}\" \\\n",
    "            f\"__fold.{config_dict['fold']}\" \\\n",
    "            f\"__type.{config_dict['model_type']}\" \\\n",
    "            f\"__epoch.{config_dict['last_epoch']}\" \\\n",
    "            f\"__user.{config_dict['uploading_user']}\" \n",
    "        long_name = long_name[:128] # Limit to wandd max artifact name size of 128\n",
    "\n",
    "        description = \"\" if user_description == DESCRIPTION_PLACEHOLDER else user_description\n",
    "        dataset_json_filepath = Path(RAW_DATA_BASE_PATH, f\"nnUNet_raw_data/{config_dict['task_name']}/dataset.json\")\n",
    "\n",
    "        with wandb.init(name=long_name, project= \"nnUNet\", job_type=\"train\", config=config_dict, notes=description) as run:\n",
    "            \n",
    "            for epoch_idx, (loss_train, loss_val, eval_dice) in \\\n",
    "                enumerate(zip(plot_data['training/loss'], plot_data['validation/loss'], plot_data['eval/dice'])):\n",
    "\n",
    "                run.log({'training/loss': loss_train, 'validation/loss':loss_val, 'eval/dice':eval_dice}, step=epoch_idx)\n",
    "            \n",
    "            for wandb_path, table in summary_tables.items():\n",
    "                # wandb_base = \"\".join(wandb_path.split(\"/\")[:-1])\n",
    "                title = \" \".join(wandb_path.split(\"/\")[-2:])\n",
    "                run.log({wandb_path[:111]: wandb.plot.bar(table, *table.columns, title=title)})\n",
    "                # artifact name cannot be longer than 128. run-bbbbbbb- is prefixed, _table is postfixed == 128-18\n",
    "\n",
    "            model_artifact = wandb.Artifact(\n",
    "                name=long_name, type=\"model\",\n",
    "                description=description,\n",
    "                metadata=metadata\n",
    "            )\n",
    "\n",
    "            if UPLOAD_MODEL_FILES:\n",
    "                model_artifact.add_file(model_pkl_path)\n",
    "                model_artifact.add_file(model_path)\n",
    "\n",
    "            for log_filepath in [_path for _path in model_basepath.iterdir() if \"training_log\" in str(_path)]:\n",
    "                model_artifact.add_file(log_filepath)\n",
    "\n",
    "            if dataset_json_filepath.is_file():\n",
    "                model_artifact.add_file(dataset_json_filepath)\n",
    "                \n",
    "            run.log_artifact(model_artifact)\n",
    "\n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "471c5e5848220fa2261bb2a4b4a25b1de56da49bb04203a0d27e69a9769bd510"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
